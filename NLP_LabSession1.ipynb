{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Lab Session: Basics of Natural Language Processing with Python\n",
        "##1. Lab Objectives\n",
        "**By the end of this session, students will be able to:**\n",
        "+ How to work with Strings (Text)\n",
        "+ How to acquire and handle text in Python.\n",
        "+ How to clean text using string operations.\n",
        "+ How to remove stopwords.\n",
        "+ How to perform word frequency analysis with a practical example.\n",
        "\n",
        "## 2. Background\n",
        "Before applying advanced NLP models, raw text must be preprocessed. Preprocessing ensures:\n",
        "\n",
        "+ **Consistency** (e.g., converting everything to lowercase).\n",
        "+ **Noise reduction** (removing punctuation, numbers, and stop words).\n",
        "+ **Useful insights** (like most frequent words)."
      ],
      "metadata": {
        "id": "9m84qrDmqCZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Strings\n",
        "In Python, a string is a sequence of characters (letters, numbers, symbols).\n",
        "Python has a set of built-in methods that you can use on strings.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "text = \"Natural Language Processing\"\n"
      ],
      "metadata": {
        "id": "xPXOr-dOFlsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1. Creating Strings"
      ],
      "metadata": {
        "id": "kzK413PaGUlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"Hello\"\n",
        "s2 = 'World'\n",
        "s3 = \"\"\"This is\n",
        "a multi-line string.\"\"\"\n",
        "print(s1, s2, s3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t8NAJL-sGRXK",
        "outputId": "8903851f-e857-40b1-82ae-344ac1e82e99"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello World This is \n",
            "a multi-line string.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Python NLP\"\n",
        "\n",
        "print(len(text))       # Length of string\n",
        "print(text[0])         # First character\n",
        "print(text[-1])        # Last character\n",
        "print(text[0:6])       # Slice (characters 0 to 5)\n",
        "print(text + \" Lab\")   # Concatenation\n",
        "print(text * 3)        # Repetition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DUCYmRPtGhHk",
        "outputId": "6d59c67f-4c09-4a09-f91c-22cc016f8090"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "P\n",
            "P\n",
            "Python\n",
            "Python NLP Lab\n",
            "Python NLPPython NLPPython NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2. Basic Operations"
      ],
      "metadata": {
        "id": "71LSxynMQwsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Python NLP\"\n",
        "\n",
        "print(len(text))       # Length of string\n",
        "print(text[0])         # First character\n",
        "print(text[-1])        # Last character\n",
        "print(text[0:6])       # Slice (characters 0 to 5)\n",
        "print(text + \" Lab\")   # Concatenation\n",
        "print(text * 3)        # Repetition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLQEWSzPQzvQ",
        "outputId": "f2a905bd-6731-40cf-baff-69492f0d3407"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "P\n",
            "P\n",
            "Python\n",
            "Python NLP Lab\n",
            "Python NLPPython NLPPython NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.3. Changing Case"
      ],
      "metadata": {
        "id": "IcOkxLMbGqPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Natural Language Processing\"\n",
        "print(s.lower())   # lowercase\n",
        "print(s.upper())   # UPPERCASE\n",
        "print(s.title())   # Title Case\n",
        "print(s.capitalize()) # First letter capitalized"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9YLmpQi4GsNe",
        "outputId": "0d9cebb0-d5ac-4bbc-c03d-85c692465840"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "natural language processing\n",
            "NATURAL LANGUAGE PROCESSING\n",
            "Natural Language Processing\n",
            "Natural language processing\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.4. Removing Unwanted Characters"
      ],
      "metadata": {
        "id": "VnVTBWEfGy6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"   NLP is fun!!!   \"\n",
        "print(s.strip())     # remove leading/trailing spaces\n",
        "print(s.rstrip(\"!\")) # remove characters from right side\n",
        "print(s.lstrip())    # remove spaces from left side"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDCZy590G3_d",
        "outputId": "70d320fd-21c4-43a2-fad4-a4e44b9e5fcc"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NLP is fun!!!\n",
            "   NLP is fun!!!   \n",
            "NLP is fun!!!   \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.5. Searching and Replacing"
      ],
      "metadata": {
        "id": "mcZEPpNKHGSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"I love Python. Python is powerful.\"\n",
        "\n",
        "print(s.find(\"Python\"))     # first occurrence\n",
        "print(s.rfind(\"Python\"))    # last occurrence\n",
        "print(s.count(\"Python\"))    # count occurrences\n",
        "print(s.replace(\"Python\", \"NLP\"))  # replace"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eY7uwIVjHcWq",
        "outputId": "3580b4ac-3db0-450f-d7cd-939abda809e3"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7\n",
            "15\n",
            "2\n",
            "I love NLP. NLP is powerful.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.6. Checking String Content"
      ],
      "metadata": {
        "id": "nmmbn9xnI6si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Python3\"\n",
        "\n",
        "print(s.isalpha())   # only letters? False (because of 3)\n",
        "print(s.isdigit())   # only digits? False\n",
        "print(\"3\".isdigit()) # only digits? True\n",
        "print(s.isalnum())   # letters and numbers? True\n",
        "print(\"hello\".islower())  # all lowercase? True\n",
        "print(\"HELLO\".isupper())  # all uppercase? True\n",
        "print(\" \".isspace())      # only spaces? True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x4njMl_aI7o-",
        "outputId": "648bfdae-33ec-48c4-dc0f-e0efc7b5705a"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "False\n",
            "False\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.7. Splitting and Joining"
      ],
      "metadata": {
        "id": "pb-FVqZfOwNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"NLP makes language processing easy\"\n",
        "\n",
        "words = s.split()   # split into words\n",
        "print(words)\n",
        "\n",
        "joined = \"-\".join(words)  # join words with hyphen\n",
        "print(joined)\n",
        "joined = \" \".join(words)  # join words with space\n",
        "print(joined)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LFQmL_KFOy2n",
        "outputId": "8dec64a3-57e7-4302-f6fb-772461ee2fd9"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NLP', 'makes', 'language', 'processing', 'easy']\n",
            "NLP-makes-language-processing-easy\n",
            "NLP makes language processing easy\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.8. String Formatting"
      ],
      "metadata": {
        "id": "Am7WlpPzPPgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Alice\"\n",
        "age = 25\n",
        "print(\"My name is {} and I am {} years old.\".format(name, age))\n",
        "print(f\"My name is {name} and I am {age} years old.\")  # f-string (modern)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "txyDYFPGPRcR",
        "outputId": "5e4c96df-c1e2-4002-f37c-6069a0c17dd8"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My name is Alice and I am 25 years old.\n",
            "My name is Alice and I am 25 years old.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.9. Practical Example: Cleaning a Sentence"
      ],
      "metadata": {
        "id": "XbjGBfu_QEsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = \"   $$$ Welcome to NLP Lab!!! 2025 ###   \"\n",
        "\n",
        "# Cleaning step by step\n",
        "clean = raw.strip()                          # remove spaces\n",
        "clean = clean.strip(\"$#\")                    # remove $ and #\n",
        "clean = clean.replace(\"!!!\", \"\")             # remove !!!\n",
        "clean = ''.join(ch for ch in clean if ch.isalpha() or ch.isspace()) # keep only letters/spaces\n",
        "clean = clean.lower()                        # lowercase\n",
        "\n",
        "print(\"Before:\", raw)\n",
        "print(\"After:\", clean)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cblgupPQQF3E",
        "outputId": "478cd250-83ec-4c29-86e6-486061a96ec0"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before:    $$$ Welcome to NLP Lab!!! 2025 ###   \n",
            "After:  welcome to nlp lab  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Lab Tasks"
      ],
      "metadata": {
        "id": "c3WJitdlqJGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 1: Acquiring/Downloading Text\n",
        "We’ll use text from an online source (Project Gutenberg) or simply define text in Python."
      ],
      "metadata": {
        "id": "oxhXlNDVrRHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: Simple text\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of Artificial Intelligence\n",
        "that enables machines to understand, interpret, and 2/3 generate human language.\n",
        "\"\"\"\n",
        "print(text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnpcpnRXsdYo",
        "outputId": "6950684d-3c3e-4eec-8f99-b2e9483cfeda"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural Language Processing (NLP) is a field of Artificial Intelligence\n",
            "that enables machines to understand, interpret, and 2/3 generate human language.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option B: Downloading text (requires requests library)\n",
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"  # Pride and Prejudice\n",
        "response = requests.get(url)\n",
        "novel_text = response.text[:1000]  # get only first 1000 characters\n",
        "#text = response.text  # get only first 1000 characters\n",
        "print(novel_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FE_QXJlxs5_S",
        "outputId": "b2ab177e-ac07-4453-efb9-07768450349c"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "﻿The Project Gutenberg eBook of Pride and Prejudice\r\n",
            "    \r\n",
            "This ebook is for the use of anyone anywhere in the United States and\r\n",
            "most other parts of the world at no cost and with almost no restrictions\r\n",
            "whatsoever. You may copy it, give it away or re-use it under the terms\r\n",
            "of the Project Gutenberg License included with this ebook or online\r\n",
            "at www.gutenberg.org. If you are not located in the United States,\r\n",
            "you will have to check the laws of the country where you are located\r\n",
            "before using this eBook.\r\n",
            "\r\n",
            "Title: Pride and Prejudice\r\n",
            "\r\n",
            "Author: Jane Austen\r\n",
            "\r\n",
            "Release date: June 1, 1998 [eBook #1342]\r\n",
            "                Most recently updated: October 29, 2024\r\n",
            "\r\n",
            "Language: English\r\n",
            "\r\n",
            "Credits: Chuck Greif and the Online Distributed Proofreading Team at http://www.pgdp.net (This file was produced from images available at The Internet Archive)\r\n",
            "\r\n",
            "\r\n",
            "*** START OF THE PROJECT GUTENBERG EBOOK PRIDE AND PREJUDICE ***\r\n",
            "                            [Illustration:\r\n",
            "\r\n",
            "                             GEORGE A\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 2: Text Cleaning and String Functions"
      ],
      "metadata": {
        "id": "zkzIlxHPtIMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercasing\n",
        "print(text)\n",
        "clean_text = text.lower()\n",
        "print(clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2X6PbsstL89",
        "outputId": "bc62efb9-6fec-44cf-fb15-095771f76b9c"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Natural Language Processing (NLP) is a field of Artificial Intelligence\n",
            "that enables machines to understand, interpret, and 2/3 generate human language.\n",
            "\n",
            "\n",
            "natural language processing (nlp) is a field of artificial intelligence\n",
            "that enables machines to understand, interpret, and 2/3 generate human language.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation\n",
        "import string, re\n",
        "clean_text = clean_text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "clean_text = re.sub(r'[“”’]','',clean_text)\n",
        "print(\"Cleaned Text:\", clean_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9qNykGYItVde",
        "outputId": "08e14ed3-969a-4441-bdef-b3d603ca63f8"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: \n",
            "natural language processing nlp is a field of artificial intelligence\n",
            "that enables machines to understand interpret and 23 generate human language\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing numbers\n",
        "clean_text = ''.join([ch for ch in clean_text if not ch.isdigit()])\n",
        "print(\"Cleaned Text:\", clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_9z208ptl7d",
        "outputId": "c36d663c-58f9-476d-84d2-13e44ab9a1db"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cleaned Text: \n",
            "natural language processing nlp is a field of artificial intelligence\n",
            "that enables machines to understand interpret and  generate human language\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 3: Removing Stop Words\n",
        "We’ll use NLTK stopwords (common words like \"the\", \"is\", \"and\")."
      ],
      "metadata": {
        "id": "AInenH4fu7Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "tokens = word_tokenize(clean_text)\n",
        "filtered_words = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "print(\"Filtered Words:\", filtered_words)\n",
        "clean_text = \" \".join(filtered_words)\n",
        "print(clean_text)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GhVKwSdwu8Ju",
        "outputId": "a18c11d2-e8bc-4a8a-f997-9b459c479c38"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filtered Words: ['natural', 'language', 'processing', 'nlp', 'field', 'artificial', 'intelligence', 'enables', 'machines', 'understand', 'interpret', 'generate', 'human', 'language']\n",
            "natural language processing nlp field artificial intelligence enables machines understand interpret generate human language\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TB3ot3xY0tzc",
        "outputId": "335daf18-9760-4d1e-bfb9-44696cca3fc4"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 4: Word Frequency Analysis (Practical Example)\n",
        "We’ll analyze the most common words in the text.\n",
        "\n",
        "**Practical Example:** If you download Pride and Prejudice (Jane Austen), you’ll see that names like Elizabeth and Darcy appear very frequently. This shows how frequency analysis can highlight main characters or themes in a book."
      ],
      "metadata": {
        "id": "UNbPCn9a1swu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count word frequencies\n",
        "word_freq = Counter(filtered_words)\n",
        "\n",
        "# Display 10 most common words\n",
        "print(\"Most Common Words:\", word_freq.most_common(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unLRU2I81w6q",
        "outputId": "c096ddb0-2200-49ac-c034-177ec587b82f"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most Common Words: [('language', 2), ('natural', 1), ('processing', 1), ('nlp', 1), ('field', 1), ('artificial', 1), ('intelligence', 1), ('enables', 1), ('machines', 1), ('understand', 1)]\n"
          ]
        }
      ]
    }
  ]
}