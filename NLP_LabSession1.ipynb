{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Lab Session: Basics of Natural Language Processing with Python\n",
        "##1. Lab Objectives\n",
        "**By the end of this session, students will be able to:**\n",
        "+ How to work with Strings (Text)\n",
        "+ How to acquire and handle text in Python.\n",
        "+ How to clean text using string operations.\n",
        "+ How to remove stopwords.\n",
        "+ How to perform word frequency analysis with a practical example.\n",
        "\n",
        "## 2. Background\n",
        "Before applying advanced NLP models, raw text must be preprocessed. Preprocessing ensures:\n",
        "\n",
        "+ **Consistency** (e.g., converting everything to lowercase).\n",
        "+ **Noise reduction** (removing punctuation, numbers, and stop words).\n",
        "+ **Useful insights** (like most frequent words)."
      ],
      "metadata": {
        "id": "9m84qrDmqCZS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##3. Strings\n",
        "In Python, a string is a sequence of characters (letters, numbers, symbols).\n",
        "Python has a set of built-in methods that you can use on strings.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "text = \"Natural Language Processing\"\n"
      ],
      "metadata": {
        "id": "xPXOr-dOFlsD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.1. Creating Strings"
      ],
      "metadata": {
        "id": "kzK413PaGUlD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s1 = \"Hello\"\n",
        "s2 = 'World'\n",
        "s3 = \"\"\"This is\n",
        "a multi-line string.\"\"\"\n",
        "print(s1, s2, s3)"
      ],
      "metadata": {
        "id": "t8NAJL-sGRXK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Python NLP\"\n",
        "\n",
        "print(len(text))       # Length of string\n",
        "print(text[0])         # First character\n",
        "print(text[-1])        # Last character\n",
        "print(text[0:6])       # Slice (characters 0 to 5)\n",
        "print(text + \" Lab\")   # Concatenation\n",
        "print(text * 3)        # Repetition"
      ],
      "metadata": {
        "id": "DUCYmRPtGhHk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3.2. Basic Operations"
      ],
      "metadata": {
        "id": "71LSxynMQwsT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Python NLP\"\n",
        "\n",
        "print(len(text))       # Length of string\n",
        "print(text[0])         # First character\n",
        "print(text[-1])        # Last character\n",
        "print(text[0:6])       # Slice (characters 0 to 5)\n",
        "print(text + \" Lab\")   # Concatenation\n",
        "print(text * 3)        # Repetition"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLQEWSzPQzvQ",
        "outputId": "3f765979-a994-4a18-f13a-26fe2cb92086"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10\n",
            "P\n",
            "P\n",
            "Python\n",
            "Python NLP Lab\n",
            "Python NLPPython NLPPython NLP\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###3. Changing Case"
      ],
      "metadata": {
        "id": "IcOkxLMbGqPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Natural Language Processing\"\n",
        "print(s.lower())   # lowercase\n",
        "print(s.upper())   # UPPERCASE\n",
        "print(s.title())   # Title Case\n",
        "print(s.capitalize()) # First letter capitalized"
      ],
      "metadata": {
        "id": "9YLmpQi4GsNe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###4. Removing Unwanted Characters"
      ],
      "metadata": {
        "id": "VnVTBWEfGy6T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"   NLP is fun!!!   \"\n",
        "print(s.strip())     # remove leading/trailing spaces\n",
        "print(s.rstrip(\"!\")) # remove characters from right side\n",
        "print(s.lstrip())    # remove spaces from left side"
      ],
      "metadata": {
        "id": "kDCZy590G3_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###5. Searching and Replacing"
      ],
      "metadata": {
        "id": "mcZEPpNKHGSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"I love Python. Python is powerful.\"\n",
        "\n",
        "print(s.find(\"Python\"))     # first occurrence\n",
        "print(s.rfind(\"Python\"))    # last occurrence\n",
        "print(s.count(\"Python\"))    # count occurrences\n",
        "print(s.replace(\"Python\", \"NLP\"))  # replace"
      ],
      "metadata": {
        "id": "eY7uwIVjHcWq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###6. Checking String Content"
      ],
      "metadata": {
        "id": "nmmbn9xnI6si"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"Python3\"\n",
        "\n",
        "print(s.isalpha())   # only letters? False (because of 3)\n",
        "print(s.isdigit())   # only digits? False\n",
        "print(\"3\".isdigit()) # only digits? True\n",
        "print(s.isalnum())   # letters and numbers? True\n",
        "print(\"hello\".islower())  # all lowercase? True\n",
        "print(\"HELLO\".isupper())  # all uppercase? True\n",
        "print(\" \".isspace())      # only spaces? True"
      ],
      "metadata": {
        "id": "x4njMl_aI7o-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###7. Splitting and Joining"
      ],
      "metadata": {
        "id": "pb-FVqZfOwNf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "s = \"NLP makes language processing easy\"\n",
        "\n",
        "words = s.split()   # split into words\n",
        "print(words)\n",
        "\n",
        "joined = \"-\".join(words)  # join words with hyphen\n",
        "print(joined)\n",
        "joined = \" \".join(words)  # join words with space\n",
        "print(joined)"
      ],
      "metadata": {
        "id": "LFQmL_KFOy2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###8. String Formatting"
      ],
      "metadata": {
        "id": "Am7WlpPzPPgj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "name = \"Alice\"\n",
        "age = 25\n",
        "print(\"My name is {} and I am {} years old.\".format(name, age))\n",
        "print(f\"My name is {name} and I am {age} years old.\")  # f-string (modern)"
      ],
      "metadata": {
        "id": "txyDYFPGPRcR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###9. Practical Example: Cleaning a Sentence"
      ],
      "metadata": {
        "id": "XbjGBfu_QEsk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw = \"   $$$ Welcome to NLP Lab!!! 2025 ###   \"\n",
        "\n",
        "# Cleaning step by step\n",
        "clean = raw.strip()                          # remove spaces\n",
        "clean = clean.strip(\"$#\")                    # remove $ and #\n",
        "clean = clean.replace(\"!!!\", \"\")             # remove !!!\n",
        "clean = ''.join(ch for ch in clean if ch.isalpha() or ch.isspace()) # keep only letters/spaces\n",
        "clean = clean.lower()                        # lowercase\n",
        "\n",
        "print(\"Before:\", raw)\n",
        "print(\"After:\", clean)"
      ],
      "metadata": {
        "id": "cblgupPQQF3E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###2. Basic Operations"
      ],
      "metadata": {
        "id": "Dcd1MUwjGdSU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##4. Lab Tasks"
      ],
      "metadata": {
        "id": "c3WJitdlqJGP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 1: Acquiring/Downloading Text\n",
        "We’ll use text from an online source (Project Gutenberg) or simply define text in Python."
      ],
      "metadata": {
        "id": "oxhXlNDVrRHN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Option A: Simple text\n",
        "text = \"\"\"\n",
        "Natural Language Processing (NLP) is a field of Artificial Intelligence\n",
        "that enables machines to understand, interpret, and 2/3 generate human language.\n",
        "\"\"\"\n",
        "print(text)"
      ],
      "metadata": {
        "id": "pnpcpnRXsdYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option B: Downloading text (requires requests library)\n",
        "import requests\n",
        "\n",
        "url = \"https://www.gutenberg.org/cache/epub/1342/pg1342.txt\"  # Pride and Prejudice\n",
        "response = requests.get(url)\n",
        "#novel_text = response.text[:1000]  # get only first 1000 characters\n",
        "text = response.text  # get only first 1000 characters\n",
        "#print(novel_text)"
      ],
      "metadata": {
        "id": "FE_QXJlxs5_S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 2: Text Cleaning and String Functions"
      ],
      "metadata": {
        "id": "zkzIlxHPtIMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lowercasing\n",
        "print(text)\n",
        "clean_text = text.lower()\n",
        "print(clean_text)"
      ],
      "metadata": {
        "id": "x2X6PbsstL89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing punctuation\n",
        "import string, re\n",
        "clean_text = clean_text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
        "clean_text = re.sub(r'[“”’]','',clean_text)\n",
        "print(\"Cleaned Text:\", clean_text)"
      ],
      "metadata": {
        "id": "9qNykGYItVde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Removing numbers\n",
        "clean_text = ''.join([ch for ch in clean_text if not ch.isdigit()])\n",
        "print(\"Cleaned Text:\", clean_text)\n"
      ],
      "metadata": {
        "id": "R_9z208ptl7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 3: Removing Stop Words\n",
        "We’ll use NLTK stopwords (common words like \"the\", \"is\", \"and\")."
      ],
      "metadata": {
        "id": "AInenH4fu7Mh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "\n",
        "tokens = word_tokenize(clean_text)\n",
        "filtered_words = [w for w in tokens if w not in stop_words]\n",
        "\n",
        "print(\"Filtered Words:\", filtered_words)\n",
        "clean_text = \" \".join(filtered_words)\n",
        "print(clean_text)\n"
      ],
      "metadata": {
        "id": "GhVKwSdwu8Ju"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(tokens)"
      ],
      "metadata": {
        "id": "TB3ot3xY0tzc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Task 4: Word Frequency Analysis (Practical Example)\n",
        "We’ll analyze the most common words in the text.\n",
        "\n",
        "**Practical Example:** If you download Pride and Prejudice (Jane Austen), you’ll see that names like Elizabeth and Darcy appear very frequently. This shows how frequency analysis can highlight main characters or themes in a book."
      ],
      "metadata": {
        "id": "UNbPCn9a1swu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "# Count word frequencies\n",
        "word_freq = Counter(filtered_words)\n",
        "\n",
        "# Display 10 most common words\n",
        "print(\"Most Common Words:\", word_freq.most_common(10))\n"
      ],
      "metadata": {
        "id": "unLRU2I81w6q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BFnUY6tO2LGd"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}